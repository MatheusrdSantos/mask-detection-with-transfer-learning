{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"build network - feature extraction.ipynb","provenance":[],"authorship_tag":"ABX9TyO+8ZHu3ilZKdd2A3BEgkYx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EIgKscNwh5ZQ"},"source":["# import the necessary packages\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.applications import imagenet_utils\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import load_img\n","from sklearn.preprocessing import LabelEncoder\n","from imutils import paths\n","import numpy as np\n","import progressbar\n","import h5py\n","import random\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRxoT9yPxVMH","executionInfo":{"status":"ok","timestamp":1631484623757,"user_tz":180,"elapsed":4557,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"75aeed0b-8cdf-4a7b-86c8-5b752105c9a3"},"source":["!pip install gdown"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.5.30)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQ52vJzZxXTS","executionInfo":{"status":"ok","timestamp":1631484633866,"user_tz":180,"elapsed":6277,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"a2e1b1aa-437d-4f81-fa3e-8dde69979678"},"source":["!gdown https://drive.google.com/uc?id=1DRuyR__pu2lw3d1QeY22v5SvXwV4U_xn"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1DRuyR__pu2lw3d1QeY22v5SvXwV4U_xn\n","To: /content/mask.zip\n","233MB [00:02, 80.4MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"qMVREIZwywx3"},"source":["!unzip mask.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTTG_HVM6ALO"},"source":["# import the necessary packages\n","import h5py\n","import os\n","\n","class HDF5DatasetWriter:\n","  def __init__(self, dims, outputPath, dataKey=\"images\",bufSize=1000):\n","    \"\"\"\n","    The constructor to HDF5DatasetWriter accepts four parameters, two of which are optional.\n","    \n","    Args:\n","    dims: controls the dimension or shape of the data we will be storing in the dataset.\n","    if we were storing the (flattened) raw pixel intensities of the 28x28 = 784 MNIST dataset, \n","    then dims=(70000, 784).\n","    outputPath: path to where our output HDF5 file will be stored on disk.\n","    datakey: The optional dataKey is the name of the dataset that will store\n","    the data our algorithm will learn from.\n","    bufSize: controls the size of our in-memory buffer, which we default to 1,000 feature\n","    vectors/images. Once we reach bufSize, weâ€™ll flush the buffer to the HDF5 dataset.\n","    \"\"\"\n","\n","    # check to see if the output path exists, and if so, raise\n","    # an exception\n","    if os.path.exists(outputPath):\n","      raise ValueError(\"The supplied `outputPath` already \"\n","        \"exists and cannot be overwritten. Manually delete \"\n","        \"the file before continuing.\", outputPath)\n","\n","    # open the HDF5 database for writing and create two datasets:\n","    # one to store the images/features and another to store the\n","    # class labels\n","    self.db = h5py.File(outputPath, \"w\")\n","    # \n","    # for resource limitations due to hard-disk space, a compression algorithm can be used, the price is the demand of computational power\n","    #\n","    self.data = self.db.create_dataset(dataKey, dims,dtype=\"float\")#compression='gzip')\n","    self.labels = self.db.create_dataset(\"labels\", (dims[0],),dtype=\"int\")\n","\n","    # store the buffer size, then initialize the buffer itself\n","    # along with the index into the datasets\n","    self.bufSize = bufSize\n","    self.buffer = {\"data\": [], \"labels\": []}\n","    self.idx = 0\n","\n","  def add(self, rows, labels):\n","    # add the rows and labels to the buffer\n","    self.buffer[\"data\"].extend(rows)\n","    self.buffer[\"labels\"].extend(labels)\n","\n","    # check to see if the buffer needs to be flushed to disk\n","    if len(self.buffer[\"data\"]) >= self.bufSize:\n","      self.flush()\n","\n","  def flush(self):\n","    # write the buffers to disk then reset the buffer\n","    i = self.idx + len(self.buffer[\"data\"])\n","    self.data[self.idx:i] = self.buffer[\"data\"]\n","    self.labels[self.idx:i] = self.buffer[\"labels\"]\n","    self.idx = i\n","    self.buffer = {\"data\": [], \"labels\": []}\n","\n","  def storeClassLabels(self, classLabels):\n","    # create a dataset to store the actual class label names,\n","    # then store the class labels\n","    dt = h5py.special_dtype(vlen=str) # `vlen=unicode` for Py2.7\n","    labelSet = self.db.create_dataset(\"label_names\",(len(classLabels),), dtype=dt)\n","    labelSet[:] = classLabels\n","\n","  def close(self):\n","    # check to see if there are any other entries in the buffer\n","    # that need to be flushed to disk\n","    if len(self.buffer[\"data\"]) > 0:\n","      self.flush()\n","\n","    # close the dataset\n","    self.db.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMLuDqpl4PGG"},"source":["def feature_extraction(dataset,output,buffer_size,bs):\n","\t\t'''\n","\t\t\tdataset: input folder with images dataset\n","\t\t\toutput: folder to store the feature extraction\n","\t\t\tbuffer_size: controls the size of our in-memory buffer\n","\t\t\tbs: batch size\n","\t\t'''\n","\n","\t\t# grab the list of images that we'll be describing then randomly\n","\t\t# shuffle them to allow for easy training and testing splits via\n","\t\t# array slicing during training time\n","\t\tprint(\"[INFO] loading images...\")\n","\t\timagePaths = list(paths.list_images(dataset))\n","\t\trandom.shuffle(imagePaths)\n","\n","\t\t# extract the class labels from the image paths then encode the\n","\t\t# labels\n","\t\tlabels = [p.split(os.path.sep)[-2] for p in imagePaths]\n","\t\tle = LabelEncoder()\n","\t\tlabels = le.fit_transform(labels)\n","\n","\t\t# load the VGG16 network\n","\t\tprint(\"[INFO] loading network...\")\n","\t\tmodel = VGG16(weights=\"imagenet\", include_top=False)\n","\n","\t\t# initialize the HDF5 dataset writer, then store the class label\n","\t\t# names in the dataset\n","\t\tdataset = HDF5DatasetWriter((len(imagePaths), 512 * 7 * 7),\n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\toutput, \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdataKey=\"features\", \n","\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbufSize=buffer_size)\n","\t\tdataset.storeClassLabels(le.classes_)\n","\n","\t\t# initialize the progress bar\n","\t\twidgets = [\"Extracting Features: \", progressbar.Percentage(), \" \", progressbar.Bar(), \" \", progressbar.ETA()]\n","\t\tpbar = progressbar.ProgressBar(maxval=len(imagePaths),widgets=widgets).start()\n","\n","\t\t# loop over the images in batches\n","\t\tfor i in np.arange(0, len(imagePaths), bs):\n","\t\t\t# extract the batch of images and labels, then initialize the\n","\t\t\t# list of actual images that will be passed through the network\n","\t\t\t# for feature extraction\n","\t\t\tbatchPaths = imagePaths[i:i + bs]\n","\t\t\tbatchLabels = labels[i:i + bs]\n","\t\t\tbatchImages = []\n","\n","\t\t\t# loop over the images and labels in the current batch\n","\t\t\tfor (j, imagePath) in enumerate(batchPaths):\n","\t\t\t\t# load the input image using the Keras helper utility\n","\t\t\t\t# while ensuring the image is resized to 224x224 pixels\n","\t\t\t\timage = load_img(imagePath, target_size=(224, 224))\n","\t\t\t\timage = img_to_array(image)\n","\n","\t\t\t\t# preprocess the image by (1) expanding the dimensions and\n","\t\t\t\t# (2) subtracting the mean RGB pixel intensity from the\n","\t\t\t\t# ImageNet dataset\n","\t\t\t\timage = np.expand_dims(image, axis=0)\n","\t\t\t\timage = imagenet_utils.preprocess_input(image)\n","\n","\t\t\t\t# add the image to the batch\n","\t\t\t\tbatchImages.append(image)\n","\n","\t\t\t# pass the images through the network and use the outputs as\n","\t\t\t# our actual features\n","\t\t\tbatchImages = np.vstack(batchImages)\n","\t\t\tfeatures = model.predict(batchImages, batch_size=bs)\n","\n","\t\t\t# reshape the features so that each image is represented by\n","\t\t\t# a flattened feature vector of the `MaxPooling2D` outputs\n","\t\t\tfeatures = features.reshape((features.shape[0], 512 * 7 * 7))\n","\n","\t\t\t# add the features and labels to our HDF5 dataset\n","\t\t\tdataset.add(features, batchLabels)\n","\t\t\tpbar.update(i)\n","\n","\t\t# close the dataset\n","\t\tdataset.close()\n","\t\tpbar.finish()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"St2icFjy4dEZ"},"source":["# import the necessary packages\n","from sklearn.neural_network  import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","import pickle\n","import h5py\n","\n","def train_and_evaluate(features_set):\n","    db = h5py.File(features_set,mode='r')\n","    print(\"Database keys {0:}\".format(list(db.keys())))\n","\n","    # open the HDF5 database for reading then determine the index of\n","    # the training and testing split, provided that this data was\n","    # already shuffled *prior* to writing it to disk\n","    i = int(db[\"labels\"].shape[0] * 0.75)\n","\n","    # define the set of parameters that we want to tune then start a\n","    # grid search where we evaluate our model for each value of C\n","    print(\"[INFO] tuning hyperparameters...\")\n","    params = {\"alpha\": [0.01, 0.001]}\n","    model = MLPClassifier(solver=\"adam\",\n","                          alpha=1e-5,\n","                          hidden_layer_sizes=(250, 100, ))\n","                        \n","\n","    model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n","    # print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n","\n","    # evaluate the model\n","    print(\"[INFO] evaluating...\")\n","    preds = model.predict(db[\"features\"][i:])\n","\n","    print(classification_report(db[\"labels\"][i:], \n","                                preds,\n","                                target_names=[str(i,'utf-8') for i in db[\"label_names\"]])\n","    )\n","    # serialize the model to disk\n","    print(\"[INFO] saving model...\")\n","    f = open(features_set.split(\"/\")[0] + \".cpickle\", \"wb\")\n","    f.write(pickle.dumps(model))\n","    f.close()\n","\n","    # close the database\n","    db.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CM8he8mKyyff","executionInfo":{"status":"ok","timestamp":1631483869780,"user_tz":180,"elapsed":7398,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"16fdd995-7e68-42b0-814b-1e3273c48d17"},"source":["model = VGG16(weights=\"imagenet\", include_top=False)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, None, None, 3)]   0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"BujiqVMK5Gk4"},"source":["dataset = \"Dataset\"\n","\n","# path to output HDF5 file\n","output  = \"hdf5/features.hdf5\"\n","\n","# size of feature extraction buffer\n","buffer_size = 1000\n","\n","# store the batch size in a convenience variable\n","bs = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxhQ1GHj7jG8"},"source":["!mkdir hdf5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJgWqqWC5MfS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631484853760,"user_tz":180,"elapsed":155873,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"f902ca71-569b-4c05-b53b-42290647ad7f"},"source":["feature_extraction(dataset,output,buffer_size,bs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] loading images...\n","[INFO] loading network...\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","58900480/58889256 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["Extracting Features: 100% |####################################| Time:  0:02:28\n"]}]},{"cell_type":"code","metadata":{"id":"ZYxcqPa08aiy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631484864562,"user_tz":180,"elapsed":465,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"98d13082-d289-4f20-ddf9-155e5bccfafb"},"source":["db = h5py.File(output,mode='r')\n","list(db.keys())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['features', 'label_names', 'labels']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"-eR-Kjjt8pE0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631484871132,"user_tz":180,"elapsed":325,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"f7151eef-0c59-49af-9b78-6f67d7df1c27"},"source":["db[\"features\"].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8982, 25088)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"o2Bxr7JK8rip"},"source":["db[\"labels\"].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvMejl_08um1"},"source":["[str(i,'utf-8') for i in db[\"label_names\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"asD1IPUN-tHX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631485826753,"user_tz":180,"elapsed":292813,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"94bdadf8-6d76-4120-cc2b-5675cc83b520"},"source":["train_and_evaluate(output)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Database keys ['features', 'label_names', 'labels']\n","[INFO] tuning hyperparameters...\n","[INFO] evaluating...\n","                       precision    recall  f1-score   support\n","\n","mask_weared_incorrect       1.00      1.00      1.00       745\n","            with_mask       0.99      0.99      0.99       750\n","         without_mask       0.99      0.99      0.99       751\n","\n","             accuracy                           0.99      2246\n","            macro avg       0.99      0.99      0.99      2246\n","         weighted avg       0.99      0.99      0.99      2246\n","\n","[INFO] saving model...\n"]}]},{"cell_type":"code","metadata":{"id":"Lv8l7c3xI4XD"},"source":["model = pickle.load(open('hdf5.cpickle', 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNPvRCS9JDif","executionInfo":{"status":"ok","timestamp":1631486439687,"user_tz":180,"elapsed":467,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"e22b2298-6b84-4288-eeaf-c2d827bf684c"},"source":["model.predict(db[\"features\"][:10])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 2, 1, 1, 1, 1, 0, 2, 0, 0])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TS2bsbQZJHio","executionInfo":{"status":"ok","timestamp":1631486442356,"user_tz":180,"elapsed":489,"user":{"displayName":"Matheus Santos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqHR5sdSw-MGk0jUISWs8ZMqqzc9ddaqSuedBbxA=s64","userId":"13680319523525147894"}},"outputId":"d1375fea-989e-477a-b9bb-691c7d0fa3b3"},"source":["db[\"labels\"][:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 2, 1, 1, 1, 1, 0, 2, 0, 0])"]},"metadata":{},"execution_count":26}]}]}